\section{Preliminaries and State-of-the-Art}\label{sec::relwork} %Analysis \& visualization of differences in tree-structured data}\label{sec::hierarichaldata}

\subsection{Introduction}
Today's storage capabilities facilitate the growing amount of data which is most often collected and stored without filtering or preprocessing.
One of the consequences is the information overload problem defined as:

\begin{itemize}
\item Irrelevant to the current task at hand.
\item Processed or presented in an inappropriate way.
\end{itemize}

To turn these issues into advantages the science called "Visual Analytics" recently became popular. 

James J. Thomas and Kristin A. Cook coined the term "Visual Analytics" in \cite{VISUAL_ANALYTICS} and defined it as: "Visual analytics is the science of analytical reasoning facilitated by interactive visual interfaces." It combines (semi-)automatic analytical analysis with interatice visualization techniques, thus emphasizes both cognitive human and electronical data processing strenghts.

Whereas the information seeking mantra is described as "overview first, zoom/filter, details on demand" Keim et al defined the Visual Analytics mantra as:

"Analyse First -
Show the Important -
Zoom, Filter and Analyse Further -
Details on Demand" \cite{keim2008visual}

This implies and confirms the important role of humans in the analysis process. As meantioned in the introduction humans are trained to interpret visual impressions but often fail in the same way to construe inappropriate representations as for instance the tabular representation of mathematical functions with lots of numbers specifying the input $x$ and the result $f(x)$). Therefore it is inevitable to assess analysts by interactive visualizations.

The Visual Analytics process proposed by Keim et al. is depicted in Fig. \ref{fig:visualanalyticsprocess}.

\begin{figure}[htb]
\center{\includegraphics[width=\textwidth - 6em]
{figures/visualanalyticsprocess}}
\caption{\label{fig:visualanalyticsprocess} Visual Analytics Process proposed by Keim et al. Presented in \cite{keim2008visual}.}
\end{figure}

Our Visual Analytics pipline is largely influenced by this process. Chapter \ref{sec::differences} describes the addition of new edit-operations in Treetank and two types of diff-algorithms. These fundamental to analytical reasoning and therefore denote Data Mining methods in Fig. \ref{fig:visualanalyticsprocess}. Models underlying the different views are built based on the output of the the difference-algorithms and thus represent directly the model entity in Fig. \ref{fig:visualanalyticsprocess}. Visualizations (Chapter \ref{sec::visualizations} receive user input and build models through invocation of an ID-based diff algorithm. Parameter changes in the GUI of our main visualization, a Sunburst view tailored to tree-structure comparisons, influence and change the models and in turn change the visualizations according to their output. However user interaction might change visualization(s) without having any impact on the model(s).

Comparing tree-structures by a Visual Analytics approach requires analytical reasoning through the computation of differences in the first place. Thus the next section describes existing ID-less algoritms focused on XML-comparison. A short study and summary of existing visualization techniques follows.

\subsection{Analysis of differences}
Line by line textual diffs are based on algorithms which solve the Longest Common Subsequence (LCS) problem. Whereas they are sufficient to track changes in flat text-files, tree-structures need more sophisticated methods as pointed out in the introduction.

The \emph{Extendable Markup Language} (XML) is a textual data format for encoding and structuring documents in machine- and human-readable form. Its inherent data structure is a rooted, ordered, labeled tree. 

\begin{mydef}
A rooted \textbf{tree-structure} is an acyclic connected graph, which starts with a root node whereas every node has zero or more children with the exception of the root-node having exactly one parent-node. We define a tree T as $T = (N, E, root(T))$ whereas N denotes all nodes, E denotes edges, the relation between child- and parent-nodes whereas each child except the root-node has exactly one parent node, root(T) defines a root-node which is the only node having no parent.
\end{mydef}

\begin{mydef}
A rooted, ordered, labeled tree is a tree-structure which extends the rooted tree-definition by defining a specific order for child nodes (that is extending the parent/child edge relation E) and a label for each node. Furthermore each node has a label. Thus T is an ordered, labeled, tree if $T = (N, E, root(T), \Lambda(n) \in \Sigma)$. $\Sigma$ is a finite alphabet and $n$ is a node in the tree.
\end{mydef}

Thus a tree is more restricted than a hierarchy based on a directed acyclic graph (DAG) in which every node except the root\footnote{which has no parent} might have one or more parent nodes.

Many algorithms have been developed to determine differences in tree-structures for instance to provide deltas, which represent a compact version of the changes to the original document.

Next, some essential terms are defined to set the stage for the upcoming sections.

The tree-to-tree correction problem tries to transform a source tree into a destination tree by edit-operations. 

\begin{mydef}
An edit-operation is an atomar operation which changes a tree.
\end{mydef}

Deltas are defined as:

\begin{mydef}
A directed delta/edit script is a sequence or set of (elementary) edit-operations which when applied to one version v1, yields another version v2.
\end{mydef}

\begin{mydef}
A symmetric delta is a directed delta which is invertible.
\end{mydef}

In the following we use the term \emph{delta} and \emph{edit script} interchangeably in the generic form meaning directed delta. Each edit operation is usually defined with a fixed cost (usually unit cost).

\begin{mydef}
A minimal edit script is a minimum cost edit script.
\end{mydef}

Besides providing a minimal or close to minimal edit script further metrics of a diff-algorithm are the CPU runtime and the compactness of the delta in terms of storage-space (e.g. it is in most cases sufficient to define edit operations on subtrees, such as a delete- or move-operation which usually removes the whole subtree).

Some of the most popular approaches to detect differences in XML-documents and to generate a delta are described next.

\subsubsection{DeltaXML\cite{DELTAXML}}
uses attributes in the deltaxml namespace to specify changes. For instance \texttt{deltaxml:deltaV2="A!=B"} specifies that the element containing this attribute has been changed from revision A to revision B. Nodes which exist in revision A but not in revision B are marked with \texttt{deltaxml:deltaV2="A"} and vice versa. Due to this, the deltas generated by DeltaXML are invertible. Elements are matched according to element types, the level in the tree and the Longest Common Sequence (LCS). Furthermore matching PCDATA nodes may optionally be prefered. Similar, attribute-IDs in the deltaxml-namespace may be used to mark nodes with unique IDs. Marking all nodes with an ID generates a minimum edit distance delta file.

\subsubsection{XyDiff\cite{cobena2002detecting}}
has been developed in the context of Xyleme, an XML database warehouse. Initially a unique persistent identifier XID is assigned to each node. XID-Maps are generated through a postorder traversal whereas initially integers from 1 to n are assigned. N denotes the number of nodes in the original tree. Added nodes in the revision to compare are assigned further integers starting from n + 1 again by a postorder traversal. Nodes which are not present in the new revision are removed resulting in gaps. Assuming an initial range of identifiers from (1-474) it might result in several ranges, for instance (1-13),(17-447),(450-474) which means that the nodes with the XIDs 14, 15 and 16 have been deleted as well as the nodes 448 and 449. The algorithm for the actual change detection is outlined in the next paragraph. Inserts, Deletes, Updates and Moves are supported.

First nodes with ID attributes defined in a DTD are matched. Then signatures are generated in a bottom-up traversal, which are hash values computed from the value of the current node and all child signatures. Furthermore weights are computed and defined as the text node sizes which are summed up for each child node. A priority queue is build, whereas the largest weights of the new document are prioritised. The largest subtrees are considered first to be matched based on their signatures. If more than one node has the same signature a heuristic is used, otherwise the child nodes are added to the queue. Whenever nodes match each subtree and anchestor pair is going to be matched as long as the labels are equal. The propagation to anchestor nodes depends on the node weight. A heuristic is used to substitute the computation of largest order preserving common subsequences for the move-operation. As heuristics are used the resulting edit-scripts/deltas are not guaranteed to be minimal.

The CPU runtime of the algorithm is $O(n \log n)$.

\subsubsection{LaDiff / Fast Match Simple Editscript (FMSE)\cite{chawathe1996change}}\label{subsec::ladiff}
operates on different versions of LaTeX documents. It has been developed to demonstrate and measure the feasability of an approach to detect changes in hierarichally structured information.

Chawathe et al. divides this task into two main problems:

\begin{description}
\item[the Good Matching problem] is the problem of finding matches between the two trees, which are either equal for some predefined function or approximately equal.
\item[finding a Minimum Conforming Edit Script (MCES)] is the second obstacle. An \emph{edit script} is a sequence of edit operations wh the source file which transform it into the target document once applied. Costs are therefore applied to every edit operation.
\end{description}

The algorithms used to solve these two problems operate on rooted, ordered, labeled trees. Four edit operations (\texttt{insert}, \texttt{delete}, \texttt{update} and \texttt{move} are defined with unit costs.

The algorithm proves to yield minimum edit scripts in case the assumption holds true that no more than one leaf node is considered equal to a predefined function which compares the values of leaf nodes and the labels match. XML does provide labels in the form of \texttt{QName}s for \texttt{element}- and \texttt{attribute}-nodes and a slightly restricted alphabet for \texttt{text}-nodes. Thus either text-node values have to be compared or \texttt{QName}s.

Thus the first criterium for leaf nodes is 

\begin{equation} 
compare(v(x), v(y)) \leq f\ such\ that\ 0 \leq f \leq 1
\end{equation}

Inner nodes are match candidates according to the forumla 

\begin{equation}
\frac{|common(x, y)|}{max(|x|,|y|)} > t\ and\ label(x) = label(y)
\end{equation}

$common(x,y) = \{(w,z) \in M | x\ contains\ w\ and\ y\ contains\ z\}$ whereas a \begin{quote}node x contains a node y if y is a leaf node descendant of x and $|x|$ denotes the number of leaf nodes x contains.\end{quote} The threshold t is defined as $0.5 \leq t \leq 1.0$.

In a first step the good matching problem is solved by means of concatenating nodes/labels starting from bottom up and finding a LCS at each level of the tree. Furthermore if nodes are left which are equal according to the predefined function they are subsequently matched on each level. If the assumption does not hold which might be the case for several XML-documents, especially in data centric XML files the algorithm yields large output-deltas according to Lindholm et al.\cite{lindholm2006fast} and R"onnau et al.\cite{ronnau2009efficient}. This is a direct result of the ambigiouty of the LCS as well as of the subsequent matching of nodes on every level. However this is a problem common to almost all differencing algorithms and can be minimized by proper definitions of the similarity functions for leaf- and innder-nodes.

After that in a breadth first traversal nodes are inserted, updated, moved and deleted. The children of each node are aligned based on the LCS once again. Nodes which are matched but not in the LCS are moved. The order in which operations are applied to the source tree and the edit script is crucial to the correctness of the algorithm.

It is apparent that a large number of moves are appended to edit scripts in case the assumption that every leaf node in the old revision is similar to at most one leaf node in the old revision. If this assumption does not hold true the algorithm yields suboptimal deltas due to mismatches. A postprocessing step reduces other mismatches and thus move-operations such that children of matched nodes, which have not the same parent are tried to match with children of the same parent in the other tree, thus correcting some misaligned nodes. Note that this step can not reduce errors propagating from mismatched leaf nodes up in the tree.

The time complexity is $O(n*e+e^2)$.

\subsubsection{X-Diff\cite{wang2003x}}
operates on unordered, labeled trees. No matter how the order among child-nodes changes it lacks semantic difference and therefore is considered to be equal. 

First XHash values are computed in a bottom up postorder traversal for every node which represent the entire subtree rooted at the respective node.
The hash computation does not include the child order, such that isomporhic trees can be matched in subsequent steps.

Next the trees are traversed starting from the root-nodes. Nodes on currentLevel+1 are filtered out which have equal hash values.

Signatures defined as $Signature(x) = /name(x_{1})/.../name(x_{n})/name(x)/type(x)$ for element nodes and $Signature(x) = /name(x_{1})/.../name(x_{n})/type(x)$ for text nodes are used to determine if nodes are considered to match. Note that in case of a text node it does not contain the value in the signature. This decision leads to the support of update-Operations, which are only defined as an edit cost for text nodes. 

Initially leaf nodes are compared based on a predefined edit distance function and a matching/distance-value tuple is stored in a table. To compute the edit distance between subtrees the minimum-cost maximum flow algorithm \cite{zhang1996constrained} is used.

Based on a minimum cost matching and the distance table an edit script can be computed.

The runtime has been considered for each of the three steps separately: 

\begin{enumerate}
\item {\bf{Parsing and Hashing}}: $O(|T_{1}| + |T_{2}|)$
\item {\bf{Mapping}}: $O(|T_{1}| \times |T_{2}|) \times max\{deg(T_{1}, deg(T_{2})\} \times \log_{2}(max\{deg(T_{1}), deg(T_{2})\}))$
\item {\bf{Generating Minimum-Cost Edit Script}}: $O(|T_{1}| + |T_{2}|)$
\end{enumerate}

\subsubsection{DocTreeDiff\cite{ronnau2009efficient}}
is designed for difference detection in document-centric XML documents. XML documents come in two-flavors. Document-centric XML documents are usually written by an author such as website-content or a DocBook-based article whereas data-centric documents are usually automatically created. Leaf nodes in document-centric XML usually can be descriminated very well.

It is stated that document-centric XML typically is restricted in depth by a document format through a Schema or DTD but the width, which grows with increasing text length, is not. Furthermore almost all content is stored in the leafes whereas internal nodes represent the structure of the document (sections, paragraphs, lists, descriptions...). Based on this observation R\"onnau et al. state the following assumptions

\begin{enumerate}
\item Content is stored within the leaves.
\item Changes to structure and markup will be performed on a higher level within the tree.
\item Many non-leaf nodes are equal due to identical markup.
\end{enumerate}

Based on these assumptions the algorithm relies heavily on the computation of a LCS on leaf nodes.

\begin{enumerate}
\item First the algorithm computes the LCS on leaf nodes based on their hash values and the depth in the tree.
\item Next, a bottom up traversal of all leaf nodes which are considered equal follows to detect updates for each anchestor node. All nodes are marked which have been processed to skip the process for subsequent bottom-up traversals when an anchestor node is the same.
\item Last, deletes, inserts and moves are detected. A second bottum up traversal starting at leaf nodes which have not matched, detects nodes which are in the old revision but not in the new are considered as being deleted. At every level the child nodes of the parents are searched for the neares node which has been marked as matched during the LCS computation. If one is found the traversal stops. The same holds for inserted nodes if the reverse condition is true. Therefore the bottom-up traversal detects the largest possible subtrees to delete or insert, since the edit operations are not defined on single nodes. Furthermore adjacent deletions or insertions are glued together. Delete/insert-operations on the same subtrees are combined into one move-Operation.
\end{enumerate}

Thus it does not detect moves if internal nodes are inserted but large subtrees have not changed. The runtime complexity is $O(leaves(T)D + n)$ whereas $T$ is the sum of nodes in both trees and $D$ is the number of edit operations. The space complexity is $O(T+D)$.

\subsubsection{Faxma\cite{lindholm2006fast}}
uses fast sequence aligning. First the input documents are parsed into XAS tokens, which preserves the XML structure. They support three edit operations: \texttt{insert}, \texttt{delete} and \texttt{move} since they claim that subtrees are often moved. Updates are nontheless handled through the combination of \texttt{delete/insert} pairs which is similar to the approach used by \emph{DocTreeDiff}. Based on \emph{rolling-hashes} a sliding window iterates over sequences derived from transforming both XML documents. A rolling-hash can be updated really fast if the right hash-function is chosen. If so, only the old value, the new value and the previous hash-value is needed \cite{RollingHash}:

\begin{equation}
h(S_{i+1}) = H(h(S_{i}), s_{i} , s_{i+n+1})
\end{equation}

To quickly find maximum length matches, window sizes of length $S = <48,32,16,8,4,2,1>$ are used.

At first all nodes are marked as $ins(node)$ in both sequences. Starting with the greatest size, matches are searched for in a zigzag-pattern, whereas matched sequences are extended alternately moving forward and backward until no further matches are found. These matches are marked with\\ $cpy([start\ index], [end\ index])$ in the sequence of the updated document. Any matching sequences are then removed from the sequence representing the old revision, finally resulting in the configuration, that only deleted nodes are left in this sequence.

Since the matches are not necessarily aligned on subtree boundaries the match-list must be transformed back into the tree-domain.

The algorithm serializes match lists in a sequential traversal, providing the \texttt{start-} and \texttt{end-tag} has been encountered. A queue of tentative node- and tree-reference tags is maintained to either discard changes partially or serialize the results. Details of this algorithm are omitted, since the resulting delta does not fit our purpose. The delta is a script which includes identifiers to matched nodes with inserted sequences between. It is thus not defined in terms of an edit script and thus not directly useful for our purpose.

\subsubsection{Summary}
The problem in common to all approaches is to efficiently compute a minimum or near minimum edit script to transform the first into the second tree. Unfortunately a guaranteed minimum edit script for the the tree-to-tree correction problem is known to be bound in the runtim by \\$O(nm\ min(depth(T1), leaves(T1))\ min(depth(T2),\ leaves(T2)))$, with $n$, $m$ denoting the number of nodes of the trees $T1$ , $T2$. Using heuristics speeds up the process but it does in most cases produce non optimal (minimal) edit scripts which might be counterintuitive to humans, because of mismatched nodes which have not been changed. Every diff-algorithm has its strength and pitfalls. Depending on the input and expected modification patterns some algorithms provide better results than others. All algorithms work best if leaf nodes can be descriminated very well. Comparing document oriented XML thus usually procudes better results in comparison to data centric XML in terms of minimum or near minimum edit-scripts/deltas.

Memory consumption is very important considering larger XML instances ranging from 1Gb and far above. Reducing the cost of computing the LCS which has a large memory footprint might be mandatory but also results in heuristics. A survey of the wide range of algorithms is summarized in \cite{cobena2002comparative}. Several algorithms are described and compared according to the attributes memory consumption, time complexity supported operations and ordered/unordered. Ordered/unordered denotes if anchestor/child relationships and the child order is considered (ordered) or not (unordered). 

In summary a trade-off between the minimality of edit scripts/operations and the memory consumption as well as the time complexity of the algorithm exists. Furthermore no algorithm exists which outperforms and in respect to the edit-script cost produces always better results than the others while comparing trees of different domains and characteristics. It heavily depends on the change pattern of the input document.

\begin{table}[tb]
\centering 
\begin{tabular}[r]{|l|c|c|c|c|} 
\hline
& \textbf{runtime comp.} & \textbf{space comp.} & \textbf{tree model} & \textbf{move support}\\
\hline
\hline
\textbf{DeltaXML} & not published & not published & not published & not published\\
\hline
\textbf{XyDiff} & $O(n \log n)$ & $O(n)$ & ordered tree & yes\\
\hline
\textbf{FMSE} & $O(n e + e^2)$ & $O(n)$ & ordered tree & yes\\
\hline
\textbf{X-Diff} & $O(n^2)$ & not published & unordered tree & no\\
\hline
\textbf{DocTreeDiff} & $O(leaves(T)D + n)$ & $O(T+D)$ & ordered tree & yes\\
\hline
\textbf{Faxma} & $O(n)$ (average) & not published & ordered tree & no\\
& $O(n^2)$ (worst) &  & & \\
\hline
\end{tabular}
\label{chap2:comparsion}
\vspace{0.5em} 
\caption{Comparsion of tree-to-tree difference algorithms.}
\end{table}

\subsection{Visualization of differences}
Several visualization techniques have been proposed for hierarichal data ranging from simple node link diagrams, force directed layouts to space filling approachs. Recently database systems which are capable of storing hierarichal temporal data efficiently and therefore store snapshots of time varying data put forth the need to determine and visualize changes between several revisions such that analysts are able to answer time dependent questions like the ones raised in the motivating application examples.

While in the past it has been possible to map temporal hierarichal data to relational databases it required the storage of a full snapshot through foreign/primary key relations instead of just storing incremental or differential updates as well as the hierarichal mapping overhead.

\subsubsection{TimeRadarTrees\cite{vilanovatimeradartrees}} To visualize weighted dynamic compound Digraphs, which are graphs with a hierarichal dimension, TimeRadarTrees have been developed. Changes of leaf nodes and their directed edges are revealed, whereas incoming edges are plotted in a radial manner as a slice on the inner circle. Outgoing edges are represented by the outer thumbnails. Therefore visual clutter regarding related nodes, which occurs in node link diagrams is avoided. The hierarchy and thus the inner nodes are drawn on top of the inner radial circle (Fig. \ref{fig:timeradar}). The leaf nodes are labeled A, B, C, D and E. Each segment of a node represents the node in a specific revision of the graph. Node D has three incoming edges in the first graph, in the second one and in the third none (inner circle). The color red denotes that the node has at least one incoming or outgoing (which depends on wether one looks at the inner or outer circles) edge. Grey scale means the node has no incoming/outgoing edges at all. As TimeRadarTrees visualize changes on leaf nodes but not the hierarchy itself they ca not be directly mapped to our task and thus are not present in the short evaluation at the end of this chapter and in table \ref{chap2:comparsion}.

\begin{figure}[tb]
\center{\includegraphics[width=\textwidth - 12.5em]
{figures/timeradar}}
\caption{\label{fig:timeradar} TimeRadarTrees illustration. Presented in \cite{vilanovatimeradartrees}.}
\end{figure}

\subsubsection{Interactive Visual Comparison of Multiple Trees\cite{bremm2011interactive}} The authors propose a prototype to compare multiple phylogenetic trees. Several views are available to analyse the trees on different levels of detail. A matrix view for instance displays pairwise tree-similarities based on a similarity score which takes overlapping subtrees into account. The similarity score depends on all nodes in a subtree including inner nodes instead of just determining overlapping leaf nodes. A histogram shows the score distribution among all nodes in all trees. The consensus tree is "a compact form of representing an 1:n comparison". The score is "the average of the scores comparing a reference tree node against its best matching unit in all other trees". The last view is a Tree Comparison View which highlights all nodes in the subtree a user marks through a linking and brushing technique in all other trees.

\subsubsection{Spiral-Treemap/Contrast-Treemap\cite{tu2007visualizing}}
Most treemap layouts suffer from abrupt significant layout changes even if the underlying data changes were rather small. The authors propose a new layout algorithm called \emph{Spiral Treemap} to improve the layout stability. Child-nodes are aligned along a spiral in each level beginning at the upper left corner. Therefore edit-operations as for instance \texttt\texttt{inserts} and \texttt{deletes} only affect local regions (Fig. \ref{fig:treemap-spiral}). Furthermore \emph{Contrast Treemaps} are proposed to visualize attribute changes. First a union tree is build to merge the two trees. Inserted and Deleted nodes are missing the corresponding attribute value in the other tree. Otherwise two attribute values are available from each tree, which are color coded in the same rectangle. The value of the "original" item is in the top left corner whereas the other value is in the bottom-right. Additionaly it is possible to encode the value depending on the occupied area. The higher the value in one tree the more area is occupied, the lower the value the fewer area is utilized. The Spiral Treemap layout algorithm is used whereas the size of the items in the Treemap is based on one of the attribute values or an aggregation function (min, max, avg). Another technique helps tracking layout changes. A background image is placed behind one of the two Treemaps representing one of the trees. It is distorted in regions which have changed due to the second Treemap layout. Regions which are extended or shrinked are also reflected in the distortion of the background image. Note, that in order to gain knowledge from the distorted texture/image a stable layout algorithm as for instance the Slice and Dice or Spiral Treemap is required. However we argue that it is not trivial to analyse strutural- as they are not explicitly visualized in the Contrast Treemap and the texture distortion depends on the layout algorithm, whereas small changes are hardly visible. Furthermore to the best of our knowledge it is not possible to determine which nodes have been deleted through the distorted texture. 

\begin{figure}[tb]
\center{\includegraphics[width=\textwidth]
{figures/treemap-spiral}}
\caption{\label{fig:treemap-spiral} Spiral Treemap. Presented in \cite{tu2007visualizing}.}
\end{figure}

\subsubsection{Treevolution\cite{theron2006hierarchical}} To visualize the evolution of hierarchical data Treevolution uses a \emph{TreeRing} metapher whereas nodes are arranged in a radial layout and each node can have arbitrary many parent nodes. Each Ring represents one snapshot and inserted nodes are placed on the appropriate ring depending on the time of insertion. However it seems edge crossings make it really hard to distinguish the hierarichal relationship between inserted nodes and their parents (Fig. \ref{fig:treevolution}). Furthermore deletions are not meantioned in the paper and thus to the best of our knowledge not handled in Treevolution.

\begin{figure}[tb]
\center{\includegraphics[width=\textwidth]
{figures/treevolution}}
\caption{\label{fig:treevolution} Treevolution. Presented in \cite{theron2006hierarchical}.}
\end{figure}

\subsubsection{TreeJuxtaposer\cite{munzner2003treejuxtaposer}}
TreeJuxtaposer is a system designed to support biologists to compare the structures of phylogenetic trees. A new comparsion algorithm to determine matching nodes in near-linear average time has been developed. Perfect matching nodes have the same labels for each of their leaf nodes. Based on a simple similarity measure ($S(A,B)$ between two sets whereas A, B is defined as $\frac{A \cup B}{A \cap B}$) they propose a method to colorize edges of non perfectly matching nodes and a rectangular magnifier to emphasize changed nodes. The visualization itself contains several revisions side by side plotted in a node link diagram. Selections and rectangular magnifications are synchronized (Fig. \ref{fig:treejuxtaposer}).

\begin{figure}[tb]
\center{\includegraphics[width=\textwidth]
{figures/treejuxtaposer}}
\caption{\label{fig:treejuxtaposer} TreeJuxtaposer. Presented in \cite{munzner2003treejuxtaposer}.}
\end{figure}

\subsubsection{Code Flows: Visualizing Structural Evolution of Source Code\cite{telea2008code}}
Two or more consecutive Icicle plots are used in the Code Flows system to visualize the evolution of source code. First, a parser constructs ASTs (Abstract Syntax Trees). Next, based on special structural difference measure which includes the Strahler number, the type distance between two nodes, the number of children and the number of nodes in the syntax trees best matching nodes are found using a top-down, recursive approach. Then horizontally mirrored icicles are drawn, whereas matching nodes are connected by spline tubes which are opaque in the center and transparent at the edges (Fig. \ref{fig:codeflows}). 

\begin{figure}[tb]
\center{\includegraphics[width=\textwidth - 15em]
{figures/codeflows}}
\caption{\label{fig:codeflows} Code Flows. Presented in \cite{telea2008code}.}
\end{figure}

\subsubsection{Ripple presentation for tree structures with historical information\cite{ishihara2006ripple}}
The Ripple presentation has been developed to visualize both evolving hierarchies and categories. Concentric circles are used to indicate the evolving hierarchy through time. Each circle represents one point in time. Nodes are plotted in a special node link layout. The root node of each subtree is in the focus of the view. Leaf nodes are arranged in ascending order meaning older nodes are drawn on circles further away from the current root of the subtree (e.g. $D(2002, leaf1) > D(2003, leaf2) > D(2004, leaf3)$, whereas $D(year, leaf)$ denotes the distance from the leaf to the parent node) (Fig. \ref{fig:ripple}. The angles of edges are application dependent and facilitate the clustering of categories through time. In the news articles example categories can be extracted from the content. For each child being in the same category the angle of the edge has to be in between the parent angle. Since the application examples require no diff-calculation and updates as well as deletions of nodes are not considered it is not useful to compare every aspect of changing tree structures.

\begin{figure}[tb]
\center{\includegraphics[width=\textwidth - 12em]
{figures/ripple}}
\caption{\label{fig:ripple} Ripple presentation. Presented in \cite{ishihara2006ripple}.}
\end{figure}

\subsubsection{Short evaluation}
Recently few visualizations of the changes between revisions of temporal tree data have been developed. Some of them are tailored to specific tasks and only partly useful for other applications. 

The use cases of \emph{TimeRadarTrees} are rather different from the ones addressed in this thesis. While changes of leaf nodes and the relationships between them are in the focus of TimeRadarTrees, determining and visualizing changes of the whole hierarchy is one of the main goals in this thesis.

\emph{Treevolution} uses a nice Treering-Metapher, meaning that a tree is evolving whereby nodes are plotted by time in ascending order in concentric circles. Unfortunately temporal hierarichal relations are hard to track because of a lot of clutter in larger trees which originates from the fact, that nodes are not restricted to one parent. Highlighting selected nodes and their parents only marginally improves on this. Furthermore deletions/updates of nodes are not addressed at all. Due to the fact that is not a space filling approach attributes of each node can not be visually encoded and the readability is reduced as labels can not be drawn inside the nodes or items itself which leads to overplotting. 

\emph{Ripple presentations} suffer from a lot of clutter consequent to label overplotting as well (Fig. \ref{fig:ripple-clutter}). In common with Treevolution deletions and updates have not been considered since the example use cases to the best of our knowledge just add nodes and categories. Due to the fact that it is also a node link representation and not a space filling approach attributes of nodes can not be visualized. Thus it is best comparable to Treevolution, but because of the more complex layout algorithm it can group nodes according to categories. 

\begin{figure}[tb]
\center{\includegraphics[width=\textwidth - 12em]
{figures/ripple-clutter}}
\caption{\label{fig:ripple-clutter} Ripple representation - label overplotting. Presented in \cite{ishihara2006ripple}.}
\end{figure}

A major disadvantage of the combination of the \emph{Spiral Treemap} layout algorithm and the \emph{Contrast Treemap} is that changes of the hierarchy are not explicitly highlighted but may be seen due to the distorted background image. Treemaps are space filling and layout child nodes recursively inside their parent node using rectangles. Thus, labels can be read without any problems if the rectangles are not too thin which occurs frequently in large trees ranging from about $50000$ nodes to a few hundred or even millions of nodes. Improving the aspect ratio of the rectangles results in Squarified Treemaps, which lack the property of ordered siblings. However trees are often ordered which is why Squarified Treemaps in general are only usable if the order is not significant.

\emph{TreeJuxtaposer} uses a node link algorithm, therefore it shares the drawbacks of other node link visualizations such as \emph{Treevolution} and the \emph{Ripple presentation}. Furthermore the fast differencing algorithm to the best of our knowledge relies on unique node labels. Furthermore Besides, non-matching subtrees are highlighted and can be magnified, which is synchronized in both side-by-side tree-views.

\emph{Code flows} is useful if determining and tracking changes in source code between several revisions is needed. It is a space filling approach which uses horizontally mirrored icicles and therefore certain attributes of nodes can be visualized besides highlighting actual tree changes. Labels are readable in smaller trees or when zoomed in because of the rectangular layout which underlies an icicle plot. Due to the spline tubes matching nodes can be tracked very well through different revisions. Even code splits and merges are easily trackable. On the downside small code changes resulting in the addition or deletion of a few nodes might not be visible at first glance.

\emph{Interactive Visual Comparison of Multiple Trees} provides very interesting capabilities to compare multiple trees. However we assume that the quadratic runtime of comparing all nodes with all other nodes will be restricted to (many) small trees. Furthermore it has not been meantioned how nodes are compared, but we assume unique labels or node identifiers are required due to phylogenetic trees.

\begin{table}[tb]
\centering 
\begin{tabular}[r]{|l|c|c|c|c|} 
\hline
& \textbf{hierarchy} & \textbf{space filling} & \textbf{readability} & \textbf{changes}\\
\hline
%\hline
%\textbf{Sunburst} & +++ & ++ & + & +++\\
\hline
\textbf{Spiral-/Contrast-Treemap} & + & ++\footnote{due to the side by side view which needs a lot of space} & ++ & ++\\
\hline
\textbf{Treevolution} & + & - & + & +\\
\hline
\textbf{Code Flows} & +++ & ++ & ++ & ++\\
\hline
\textbf{Juxtaposer} & ++ & - & ++ & +++\\
\hline
\textbf{Ripple Presentation} & + & - & + & +\\
\hline
\textbf{IVCoMT} & +++ & - & ++ & ++ \\
\hline
\end{tabular}
\label{chap2:comparsion}
\vspace{0.5em} 
\caption{Comparsion of tree-to-tree differences visualizations, whereas "-" is used to indicate the absence of an attribute and "+" to "+++" implies how good or bad the attribute is supported.}
\end{table}

Table \ref{chap2:comparsion} summarizes these conclusions. All visualizations are compared according to several attributes. The first column denotes how well the hierarchy is represented. The second column indicates if a space filling approach is used and to which extend the whole display space is utilized. The third column characterizes how well labels as well as the whole visualization is readable. The last column is the most significant. It determines how well and to which extent changes are visualized. Even deletions are not considered in some cases which might be due to the use cases of the respective visualization. Note that the ratings range from "-", not present to "+++".






